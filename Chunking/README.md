# 🏠🌳👨‍🦱 HTP 해석 텍스트 전처리 및 청킹

## 💡 프로젝트 개요

이 프로젝트는 **HTP (House-Tree-Person) 그림 검사 해석본** 텍스트를 RAG (Retrieval-Augmented Generation) 시스템에 사용하기 위해 전처리하고 청킹(Chunking)하는 과정을 담고 있습니다.

목표는 원본 텍스트를 의미 단위로 정확하게 분할하고, 각 청크에 **'집', '나무', '사람'** 카테고리 메타데이터를 태깅하여, 이후 임베딩 모델 학습 및 검색 시스템의 정확도를 향상시키는 것입니다.

---

## 🛠️ 주요 코드 실행 단계

### 1. 텍스트 로드 및 청킹 (Chunking)

텍스트 파일을 로드하고 정규 표현식을 사용하여 구조화된 청크를 생성합니다.

* **파일 로드:** `/content/브런치_집-나무-사람 해석 수기본.txt`
* **1차 분리:** **번호 + 마침표** (`\d+\.`)를 기준으로 주요 항목을 청크로 분리합니다.
* **2차 분리:** 청크 내 **`■` 또는 `*` 기호**를 기준으로 한 번 더 분리하여 세부 항목을 추출합니다.

### 2. 카테고리 태깅 및 메타데이터 추가

각 청크의 내용을 분석하여 HTP 3요소 카테고리를 할당하고 `Document` 객체로 변환합니다.

| 구분 | 함수/로직 | 내용 |
| :--- | :--- | :--- |
| **카테고리 감지** | `detect_category(text)` | 텍스트 내 `"집"`, `"나무"`, `"사람"` 키워드 포함 여부로 초기 카테고리 할당. |
| **수동 보정** | 인덱스 기반 수정 | 초기 자동 감지 후, **인덱스 범위**를 지정하여 대규모 카테고리(집, 나무, 사람)를 수동으로 재할당하여 정확도 확보. |
| **결과** | `langchain_docs` | `page_content`(청크 텍스트)와 `metadata`(`chunk_index`, `category`)를 포함하는 `Document` 리스트 생성. |

### 3. 데이터 정제 (Filtering)

학습 데이터의 품질을 높이기 위해 길이가 짧거나 불필요한 청크를 제거합니다.

* **필터링 조건:** 청크 내용의 길이가 **10자 이하**인 문서 제거.
* **결과:** 총 194개 청크 중 3개 제거되어 **191개**의 최종 학습 데이터 문서(`langchain_docs`) 확보.

---

## ✅ 최종 결과물

전처리 및 청킹 과정을 통해 생성된 `langchain_docs`는 HTP 도메인에 특화된 텍스트 데이터셋으로, 이후 **임베딩 모델 파인튜닝** 단계에서 긍정 쌍(Positive Pair)을 만드는 **코퍼스(Corpus)**로 사용됩니다.
